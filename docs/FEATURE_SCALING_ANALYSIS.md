# Feature Scaling/Normalization Analizi ve Planlama

## ğŸ“Š Mevcut Durum Analizi

### Proje Ã–zeti
- **Proje Tipi**: Bitcoin/USDT kripto para trading sinyali tahmin (Binary Classification: Long/Short)
- **Model**: LightGBM (Gradient Boosting)
- **Feature SayÄ±sÄ±**: ~64 feature (target ve datetime hariÃ§)

### Mevcut Feature Kategorileri

#### 1. **OHLCV Verileri** (Scale edilmeli)
- `open`, `high`, `low`, `close`: ~46,000 - 70,000 arasÄ±
- `volume`: Binlerce deÄŸer

#### 2. **Trend GÃ¶stergeleri** (Scale edilmeli)
- `sma_7`, `sma_14`, `sma_21`, `sma_50`, `sma_200`: Fiyat Ã¶lÃ§eÄŸinde (~46k-70k)
- `ema_12`, `ema_26`: Fiyat Ã¶lÃ§eÄŸinde

#### 3. **Momentum GÃ¶stergeleri** (KÄ±smen scale edilmeli)
- `rsi`, `rsi_7`, `rsi_21`: 0-100 arasÄ± (zaten normalize)
- `macd`, `macd_signal`, `macd_hist`: YÃ¼zlerce deÄŸer (scale edilmeli)
- `stoch_k`, `stoch_d`: 0-100 arasÄ± (zaten normalize)

#### 4. **Volatilite GÃ¶stergeleri** (Scale edilmeli)
- `bb_upper`, `bb_middle`, `bb_lower`: Fiyat Ã¶lÃ§eÄŸinde
- `bb_width`: 0.05-0.07 gibi kÃ¼Ã§Ã¼k deÄŸerler (scale edilmeli)
- `bb_position`: 0-1 arasÄ± (zaten normalize)
- `atr`: YÃ¼zlerce deÄŸer
- `adx`, `adx_pos`, `adx_neg`: 0-100 arasÄ± (zaten normalize)

#### 5. **Volume GÃ¶stergeleri** (Scale edilmeli)
- `volume_sma`: Binlerce deÄŸer
- `volume_ratio`: Oran (scale edilebilir ama gerekli deÄŸil)

#### 6. **Fiyat Feature'larÄ±** (KÄ±smen scale edilmeli)
- `returns`, `returns_5`, `returns_10`, `returns_20`: -0.1 ile 0.1 arasÄ± (Ã§ok kÃ¼Ã§Ã¼k)
- `high_low_ratio`, `close_open_ratio`: Oranlar (~1.0 civarÄ±)
- `price_position`: 0-1 arasÄ± (zaten normalize)
- `close_lag_*`: Fiyat Ã¶lÃ§eÄŸinde
- `volume_lag_*`: Volume Ã¶lÃ§eÄŸinde
- `volatility_*`: Ã‡ok kÃ¼Ã§Ã¼k deÄŸerler (0.002-0.008 arasÄ±)
- `close_max_*`, `close_min_*`: Fiyat Ã¶lÃ§eÄŸinde

#### 7. **Zaman Feature'larÄ±** (Scale edilmemeli)
- `hour`: 0-23 (categorical)
- `day_of_week`: 0-6 (categorical)
- `month`: 1-12 (categorical)
- `is_weekend`: 0-1 (binary)

#### 8. **Target Variables** (Scale edilmemeli)
- `target`: Binary (0/1)
- `future_return`: Regression target

### Ã–lÃ§ek FarklÄ±lÄ±klarÄ±

| Feature Kategorisi | Ã–lÃ§ek AralÄ±ÄŸÄ± | Ã–rnek DeÄŸerler |
|-------------------|---------------|----------------|
| Fiyatlar | 46,000 - 70,000 | close, open, high, low |
| Volume | 500 - 5,000 | volume, volume_sma |
| Returns | -0.1 - 0.1 | returns, returns_5, returns_10 |
| Volatility | 0.002 - 0.008 | volatility_7, volatility_14 |
| RSI/ADX | 0 - 100 | rsi, adx, stoch_k |
| Ratios | 0.9 - 1.1 | high_low_ratio, close_open_ratio |
| MACD | -500 - 500 | macd, macd_signal |
| BB Width | 0.05 - 0.07 | bb_width |

## ğŸ¯ Feature Scaling Gerekli mi?

### LightGBM iÃ§in Durum
- **Tree-based modeller** (LightGBM, XGBoost, Random Forest) genelde scaling'e ihtiyaÃ§ duymaz
- Ancak bazÄ± durumlarda faydalÄ± olabilir:
  - Feature importance karÅŸÄ±laÅŸtÄ±rmalarÄ±
  - Hyperparameter tuning stabilitesi
  - Model interpretability

### Gelecek Modeller iÃ§in Durum
- **Neural Networks**: Kesinlikle gerekli
- **SVM**: Kesinlikle gerekli
- **Logistic Regression**: Kesinlikle gerekli
- **K-Means Clustering**: Kesinlikle gerekli
- **PCA**: Kesinlikle gerekli

### SonuÃ§
âœ… **Feature scaling eklenmeli** Ã§Ã¼nkÃ¼:
1. Gelecekteki model deÄŸiÅŸikliklerine hazÄ±rlÄ±klÄ± olur
2. Feature importance karÅŸÄ±laÅŸtÄ±rmalarÄ±nÄ± daha anlamlÄ± hale getirir
3. Model interpretability'yi artÄ±rÄ±r
4. Production pipeline'Ä±nda tutarlÄ±lÄ±k saÄŸlar

## ğŸ—ï¸ ModÃ¼ler Mimari PlanÄ±

### KlasÃ¶r YapÄ±sÄ±
```
src/
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # BaseScaler abstract class
â”‚   â”œâ”€â”€ scalers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ standard.py      # StandardScaler wrapper
â”‚   â”‚   â”œâ”€â”€ minmax.py        # MinMaxScaler wrapper
â”‚   â”‚   â”œâ”€â”€ robust.py        # RobustScaler wrapper
â”‚   â”‚   â””â”€â”€ quantile.py       # QuantileTransformer wrapper
â”‚   â””â”€â”€ preprocessor.py      # Ana Preprocessor sÄ±nÄ±fÄ±
```

### SÄ±nÄ±f TasarÄ±mÄ±

#### 1. BaseScaler (Abstract Base Class)
```python
class BaseScaler(ABC):
    """Base scaler interface"""
    
    @abstractmethod
    def fit(self, X: pd.DataFrame) -> 'BaseScaler':
        """Fit scaler on training data"""
        
    @abstractmethod
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Transform data"""
        
    @abstractmethod
    def fit_transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Fit and transform"""
        
    @abstractmethod
    def inverse_transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Inverse transform (for predictions)"""
```

#### 2. Concrete Scalers
- `StandardScaler`: Mean=0, Std=1 (outlier'lara hassas)
- `MinMaxScaler`: 0-1 arasÄ± (outlier'lara hassas)
- `RobustScaler`: Median ve IQR kullanÄ±r (outlier'lara dayanÄ±klÄ±) â­ **Ã–nerilen**
- `QuantileTransformer`: Uniform veya normal daÄŸÄ±lÄ±m (non-linear)

#### 3. Preprocessor SÄ±nÄ±fÄ±
```python
class Preprocessor:
    """Ana preprocessing sÄ±nÄ±fÄ±"""
    
    def __init__(self, config=None):
        self.config = config or get_config()
        self.scaler = None
        self.feature_columns = None
        self.excluded_columns = None
        
    def fit(self, df: pd.DataFrame) -> 'Preprocessor':
        """Fit scaler on training data"""
        
    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transform data (train/test)"""
        
    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Fit and transform"""
        
    def save_scaler(self, filepath: str) -> None:
        """Save scaler for production"""
        
    def load_scaler(self, filepath: str) -> None:
        """Load scaler for production"""
```

### Config Entegrasyonu

```python
@dataclass
class PreprocessingConfig:
    """Preprocessing konfigÃ¼rasyonu"""
    
    # Scaling ayarlarÄ±
    enable_scaling: bool = True
    scaler_type: str = "robust"  # 'standard', 'minmax', 'robust', 'quantile'
    
    # Hangi kolonlar scale edilmeyecek
    exclude_columns: List[str] = field(default_factory=lambda: [
        'datetime',
        'target',
        'future_return',
        'hour',
        'day_of_week',
        'month',
        'is_weekend',
        'rsi', 'rsi_7', 'rsi_21',  # Zaten 0-100 arasÄ±
        'stoch_k', 'stoch_d',  # Zaten 0-100 arasÄ±
        'adx', 'adx_pos', 'adx_neg',  # Zaten 0-100 arasÄ±
        'bb_position',  # Zaten 0-1 arasÄ±
        'price_position',  # Zaten 0-1 arasÄ±
    ])
    
    # Scaler parametreleri
    robust_quantile_range: Tuple[float, float] = (0.25, 0.75)
    standard_with_mean: bool = True
    standard_with_std: bool = True
    minmax_feature_range: Tuple[float, float] = (0, 1)
```

## ğŸ”„ Pipeline Entegrasyonu

### Mevcut Pipeline
```
Data Collection â†’ Feature Engineering â†’ Model Training
```

### Yeni Pipeline
```
Data Collection â†’ Feature Engineering â†’ Preprocessing (Scaling) â†’ Model Training
```

### KullanÄ±m SenaryolarÄ±

#### Senaryo 1: Feature Engineering SonrasÄ±
```python
# Feature engineering
fe = FeatureEngineer()
df_features = fe.create_features(df_raw)

# Preprocessing (scaling)
preprocessor = Preprocessor()
df_scaled = preprocessor.fit_transform(df_features)

# Model training
X = df_scaled.drop(['target', 'datetime'], axis=1)
y = df_scaled['target']
```

#### Senaryo 2: Train/Test Split SonrasÄ±
```python
# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Fit scaler on training data only
preprocessor = Preprocessor()
X_train_scaled = preprocessor.fit_transform(X_train)
X_test_scaled = preprocessor.transform(X_test)  # Only transform, don't fit!
```

## ğŸ“ˆ Beklenen SonuÃ§lar ve Faydalar

### 1. Model PerformansÄ±
- **LightGBM**: Minimal etki (tree-based olduÄŸu iÃ§in)
- **Gelecek modeller**: Kritik fayda (neural network, SVM vb.)

### 2. Feature Importance
- Daha anlamlÄ± karÅŸÄ±laÅŸtÄ±rmalar
- Ã–lÃ§ek farklÄ±lÄ±klarÄ±ndan kaynaklanan yanlÄ±ÅŸ yorumlamalarÄ±n Ã¶nlenmesi

### 3. Hyperparameter Tuning
- Daha stabil sonuÃ§lar
- Learning rate gibi parametrelerin daha tutarlÄ± Ã§alÄ±ÅŸmasÄ±

### 4. Model Interpretability
- Feature'larÄ±n etkilerini daha iyi anlama
- SHAP deÄŸerleri gibi interpretability tool'larÄ± iÃ§in hazÄ±rlÄ±k

### 5. Production HazÄ±rlÄ±ÄŸÄ±
- Scaler'larÄ±n kaydedilmesi ve yÃ¼klenmesi
- Yeni veriler iÃ§in tutarlÄ± preprocessing

### 6. Gelecek HazÄ±rlÄ±ÄŸÄ±
- Neural network, SVM gibi modellere geÃ§iÅŸ kolaylaÅŸÄ±r
- Ensemble modeller iÃ§in hazÄ±rlÄ±k

## âš ï¸ Dikkat Edilmesi Gerekenler

### 1. Data Leakage Ã–nleme
- âœ… Scaler'Ä± **sadece training data** Ã¼zerinde fit et
- âœ… Test data'yÄ± **sadece transform** et (fit etme!)
- âœ… Production'da aynÄ± scaler'Ä± kullan

### 2. Target Variable
- âŒ Target variable'Ä± **asla scale etme**
- âŒ `future_return` gibi regression target'larÄ± scale etme

### 3. Categorical Features
- âŒ Datetime, hour, day_of_week gibi categorical feature'larÄ± scale etme
- âœ… One-hot encoding veya label encoding kullan

### 4. Zaten Normalize Olan Feature'lar
- RSI, ADX, Stochastic gibi 0-100 arasÄ± feature'lar opsiyonel
- Returns gibi zaten kÃ¼Ã§Ã¼k deÄŸerler opsiyonel
- Ancak tutarlÄ±lÄ±k iÃ§in hepsini scale etmek de mantÄ±klÄ±

### 5. Outlier Handling
- RobustScaler outlier'lara dayanÄ±klÄ± (Ã¶nerilen)
- StandardScaler ve MinMaxScaler outlier'lara hassas

## ğŸ¯ Ã–nerilen YaklaÅŸÄ±m

### 1. Scaler SeÃ§imi
**RobustScaler** Ã¶nerilir Ã§Ã¼nkÃ¼:
- Outlier'lara dayanÄ±klÄ± (kripto piyasasÄ±nda Ã¶nemli)
- Median ve IQR kullanÄ±r (daha robust)
- Tree-based modeller iÃ§in yeterli

### 2. Exclude Listesi
```python
exclude_columns = [
    'datetime',
    'target',
    'future_return',
    'hour',
    'day_of_week',
    'month',
    'is_weekend',
]
```

### 3. Pipeline SÄ±rasÄ±
1. Feature Engineering
2. Train/Test Split
3. Fit scaler on training data
4. Transform both train and test
5. Model Training

## ğŸ“ Implementation Checklist

- [ ] `src/preprocessing/` klasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur
- [ ] `BaseScaler` abstract class'Ä± oluÅŸtur
- [ ] `StandardScaler`, `MinMaxScaler`, `RobustScaler`, `QuantileTransformer` wrapper'larÄ± oluÅŸtur
- [ ] `Preprocessor` ana sÄ±nÄ±fÄ±nÄ± oluÅŸtur
- [ ] `PreprocessingConfig` config'e ekle
- [ ] Unit testler yaz
- [ ] Feature engineering pipeline'Ä±na entegre et
- [ ] Model training pipeline'Ä±na entegre et
- [ ] Scaler save/load fonksiyonlarÄ±nÄ± ekle
- [ ] DokÃ¼mantasyon gÃ¼ncelle

## ğŸ” Ã–zeleÅŸtiri

### DetaylÄ± Ä°ncelenmesi Gerekenler
1. âœ… Feature Ã¶lÃ§ekleri analiz edildi
2. âœ… Mevcut pipeline yapÄ±sÄ± incelendi
3. âœ… Config yapÄ±sÄ± incelendi
4. âœ… Model tipi (LightGBM) dikkate alÄ±ndÄ±
5. âš ï¸ Model training modÃ¼lÃ¼ henÃ¼z yok - bu entegrasyon iÃ§in Ã¶nemli
6. âš ï¸ Production deployment senaryosu dÃ¼ÅŸÃ¼nÃ¼lmeli
7. âš ï¸ Backtesting modÃ¼lÃ¼ ile uyumluluk kontrol edilmeli

### ÅÃ¼pheli Durumlar
- Model training modÃ¼lÃ¼ henÃ¼z yok, bu yÃ¼zden entegrasyon tam planlanamadÄ±
- Backtesting modÃ¼lÃ¼ var mÄ± kontrol edilmeli (scaling'in geri alÄ±nmasÄ± gerekebilir)
- Production'da scaler'larÄ±n nasÄ±l yÃ¶netileceÄŸi detaylandÄ±rÄ±lmalÄ±

