# Feature Scaling Implementation Plan

## ğŸ¯ Genel BakÄ±ÅŸ

Bu dokÃ¼man, feature scaling/normalization modÃ¼lÃ¼nÃ¼n modÃ¼ler ve modern bir ÅŸekilde implementasyon planÄ±nÄ± iÃ§erir.

## ğŸ“ KlasÃ¶r YapÄ±sÄ±

```
src/
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # BaseScaler abstract class
â”‚   â”œâ”€â”€ scalers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ standard.py      # StandardScaler wrapper
â”‚   â”‚   â”œâ”€â”€ minmax.py        # MinMaxScaler wrapper
â”‚   â”‚   â”œâ”€â”€ robust.py        # RobustScaler wrapper
â”‚   â”‚   â””â”€â”€ quantile.py      # QuantileTransformer wrapper
â”‚   â””â”€â”€ preprocessor.py      # Ana Preprocessor sÄ±nÄ±fÄ±
```

## ğŸ—ï¸ DetaylÄ± TasarÄ±m

### 1. BaseScaler (Abstract Base Class)

**Dosya**: `src/preprocessing/base.py`

```python
from abc import ABC, abstractmethod
import pandas as pd
from typing import List, Optional

class BaseScaler(ABC):
    """Base scaler interface - sklearn transformer pattern"""
    
    def __init__(self, exclude_columns: Optional[List[str]] = None):
        self.exclude_columns = exclude_columns or []
        self.feature_columns: Optional[List[str]] = None
        self.scaler = None
        
    @abstractmethod
    def _create_scaler(self):
        """Create the underlying sklearn scaler"""
        pass
    
    def fit(self, X: pd.DataFrame) -> 'BaseScaler':
        """Fit scaler on training data"""
        # Determine feature columns
        # Fit scaler
        return self
    
    @abstractmethod
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Transform data"""
        pass
    
    def fit_transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Fit and transform"""
        return self.fit(X).transform(X)
    
    @abstractmethod
    def inverse_transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Inverse transform (for predictions)"""
        pass
    
    def _get_feature_columns(self, df: pd.DataFrame) -> List[str]:
        """Get columns to scale (exclude specified columns)"""
        return [col for col in df.columns if col not in self.exclude_columns]
```

### 2. Concrete Scalers

#### StandardScaler Wrapper
**Dosya**: `src/preprocessing/scalers/standard.py`

```python
from sklearn.preprocessing import StandardScaler as SklearnStandardScaler
from ..base import BaseScaler
import pandas as pd

class StandardScaler(BaseScaler):
    """StandardScaler wrapper - Mean=0, Std=1"""
    
    def __init__(self, exclude_columns=None, with_mean=True, with_std=True):
        super().__init__(exclude_columns)
        self.with_mean = with_mean
        self.with_std = with_std
    
    def _create_scaler(self):
        return SklearnStandardScaler(with_mean=self.with_mean, with_std=self.with_std)
    
    # Implement fit, transform, inverse_transform
```

#### RobustScaler Wrapper (Ã–nerilen)
**Dosya**: `src/preprocessing/scalers/robust.py`

```python
from sklearn.preprocessing import RobustScaler as SklearnRobustScaler
from ..base import BaseScaler
import pandas as pd

class RobustScaler(BaseScaler):
    """RobustScaler wrapper - Median and IQR based (outlier resistant)"""
    
    def __init__(self, exclude_columns=None, quantile_range=(0.25, 0.75)):
        super().__init__(exclude_columns)
        self.quantile_range = quantile_range
    
    def _create_scaler(self):
        return SklearnRobustScaler(quantile_range=self.quantile_range)
    
    # Implement fit, transform, inverse_transform
```

#### MinMaxScaler Wrapper
**Dosya**: `src/preprocessing/scalers/minmax.py`

```python
from sklearn.preprocessing import MinMaxScaler as SklearnMinMaxScaler
from ..base import BaseScaler
import pandas as pd

class MinMaxScaler(BaseScaler):
    """MinMaxScaler wrapper - Scale to 0-1 range"""
    
    def __init__(self, exclude_columns=None, feature_range=(0, 1)):
        super().__init__(exclude_columns)
        self.feature_range = feature_range
    
    def _create_scaler(self):
        return SklearnMinMaxScaler(feature_range=self.feature_range)
    
    # Implement fit, transform, inverse_transform
```

#### QuantileTransformer Wrapper
**Dosya**: `src/preprocessing/scalers/quantile.py`

```python
from sklearn.preprocessing import QuantileTransformer as SklearnQuantileTransformer
from ..base import BaseScaler
import pandas as pd

class QuantileTransformer(BaseScaler):
    """QuantileTransformer wrapper - Uniform or normal distribution"""
    
    def __init__(self, exclude_columns=None, n_quantiles=1000, output_distribution='uniform'):
        super().__init__(exclude_columns)
        self.n_quantiles = n_quantiles
        self.output_distribution = output_distribution
    
    def _create_scaler(self):
        return SklearnQuantileTransformer(
            n_quantiles=self.n_quantiles,
            output_distribution=self.output_distribution
        )
    
    # Implement fit, transform, inverse_transform
```

### 3. Preprocessor (Ana SÄ±nÄ±f)

**Dosya**: `src/preprocessing/preprocessor.py`

```python
import pandas as pd
import pickle
from pathlib import Path
from typing import Optional, List
from ..config import get_config
from ..logger import get_logger
from .scalers import RobustScaler, StandardScaler, MinMaxScaler, QuantileTransformer

logger = get_logger("MLProject.Preprocessing")

class Preprocessor:
    """Ana preprocessing sÄ±nÄ±fÄ± - Scaling iÅŸlemlerini yÃ¶netir"""
    
    def __init__(self, config=None):
        self.config = config or get_config()
        self.scaler = None
        self.feature_columns: Optional[List[str]] = None
        self.excluded_columns: Optional[List[str]] = None
        
    def _create_scaler(self):
        """Config'e gÃ¶re scaler oluÅŸtur"""
        preprocess_config = self.config.preprocessing
        exclude_cols = preprocess_config.exclude_columns
        
        scaler_type = preprocess_config.scaler_type.lower()
        
        if scaler_type == "standard":
            return StandardScaler(
                exclude_columns=exclude_cols,
                with_mean=preprocess_config.standard_with_mean,
                with_std=preprocess_config.standard_with_std
            )
        elif scaler_type == "minmax":
            return MinMaxScaler(
                exclude_columns=exclude_cols,
                feature_range=preprocess_config.minmax_feature_range
            )
        elif scaler_type == "robust":
            return RobustScaler(
                exclude_columns=exclude_cols,
                quantile_range=preprocess_config.robust_quantile_range
            )
        elif scaler_type == "quantile":
            return QuantileTransformer(
                exclude_columns=exclude_cols,
                n_quantiles=preprocess_config.quantile_n_quantiles,
                output_distribution=preprocess_config.quantile_output_distribution
            )
        else:
            raise ValueError(f"GeÃ§ersiz scaler_type: {scaler_type}")
    
    def fit(self, df: pd.DataFrame) -> 'Preprocessor':
        """Fit scaler on training data"""
        if not self.config.preprocessing.enable_scaling:
            logger.info("âš ï¸  Scaling devre dÄ±ÅŸÄ±, atlanÄ±yor...")
            return self
        
        logger.info("ğŸ”§ Scaler fit ediliyor...")
        self.scaler = self._create_scaler()
        self.scaler.fit(df)
        self.feature_columns = self.scaler.feature_columns
        self.excluded_columns = self.scaler.exclude_columns
        
        logger.info(f"âœ… Scaler fit edildi. {len(self.feature_columns)} feature scale edilecek.")
        logger.info(f"   Excluded columns: {len(self.excluded_columns)}")
        
        return self
    
    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transform data (train/test)"""
        if not self.config.preprocessing.enable_scaling:
            return df
        
        if self.scaler is None:
            raise ValueError("Scaler henÃ¼z fit edilmedi. Ã–nce fit() Ã§aÄŸrÄ±lmalÄ±.")
        
        logger.info("ğŸ”„ Veri transform ediliyor...")
        df_scaled = self.scaler.transform(df)
        logger.info("âœ… Veri transform edildi.")
        
        return df_scaled
    
    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Fit and transform"""
        return self.fit(df).transform(df)
    
    def save_scaler(self, filepath: Optional[str] = None) -> str:
        """Save scaler for production"""
        if self.scaler is None:
            raise ValueError("Scaler henÃ¼z fit edilmedi.")
        
        if filepath is None:
            models_dir = self.config.paths.models_dir
            filepath = models_dir / "scaler.pkl"
        
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        
        with open(filepath, 'wb') as f:
            pickle.dump({
                'scaler': self.scaler,
                'feature_columns': self.feature_columns,
                'excluded_columns': self.excluded_columns
            }, f)
        
        logger.info(f"ğŸ’¾ Scaler kaydedildi: {filepath}")
        return str(filepath)
    
    def load_scaler(self, filepath: str) -> 'Preprocessor':
        """Load scaler for production"""
        with open(filepath, 'rb') as f:
            data = pickle.load(f)
        
        self.scaler = data['scaler']
        self.feature_columns = data['feature_columns']
        self.excluded_columns = data['excluded_columns']
        
        logger.info(f"ğŸ“‚ Scaler yÃ¼klendi: {filepath}")
        return self
```

### 4. Config Entegrasyonu

**Dosya**: `src/config.py` (ekleme)

```python
@dataclass
class PreprocessingConfig:
    """Preprocessing konfigÃ¼rasyonu"""
    
    # Scaling ayarlarÄ±
    enable_scaling: bool = True
    scaler_type: str = "robust"  # 'standard', 'minmax', 'robust', 'quantile'
    
    # Hangi kolonlar scale edilmeyecek
    exclude_columns: List[str] = field(default_factory=lambda: [
        'datetime',
        'target',
        'future_return',
        'hour',
        'day_of_week',
        'month',
        'is_weekend',
    ])
    
    # RobustScaler parametreleri
    robust_quantile_range: Tuple[float, float] = (0.25, 0.75)
    
    # StandardScaler parametreleri
    standard_with_mean: bool = True
    standard_with_std: bool = True
    
    # MinMaxScaler parametreleri
    minmax_feature_range: Tuple[float, float] = (0, 1)
    
    # QuantileTransformer parametreleri
    quantile_n_quantiles: int = 1000
    quantile_output_distribution: str = 'uniform'  # 'uniform' or 'normal'

# Config sÄ±nÄ±fÄ±na ekleme
@dataclass
class Config:
    # ... mevcut alanlar ...
    preprocessing: Optional[PreprocessingConfig] = None
    
    def __post_init__(self):
        # ... mevcut kod ...
        if self.preprocessing is None:
            self.preprocessing = PreprocessingConfig()
```

## ğŸ”„ Pipeline Entegrasyonu

### Senaryo 1: Feature Engineering SonrasÄ±

```python
from src.feature_engineering import FeatureEngineer
from src.preprocessing import Preprocessor

# Feature engineering
fe = FeatureEngineer()
df_features = fe.create_features(df_raw)

# Preprocessing (scaling)
preprocessor = Preprocessor()
df_scaled = preprocessor.fit_transform(df_features)

# Model training iÃ§in hazÄ±r
X = df_scaled.drop(['target', 'datetime'], axis=1)
y = df_scaled['target']
```

### Senaryo 2: Train/Test Split SonrasÄ± (Ã–nerilen)

```python
from sklearn.model_selection import train_test_split
from src.preprocessing import Preprocessor

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Fit scaler on training data only
preprocessor = Preprocessor()
X_train_scaled = preprocessor.fit_transform(X_train)
X_test_scaled = preprocessor.transform(X_test)  # Only transform!

# Model training
model.fit(X_train_scaled, y_train)
predictions = model.predict(X_test_scaled)
```

## ğŸ“ Implementation AdÄ±mlarÄ±

### AdÄ±m 1: KlasÃ¶r YapÄ±sÄ±nÄ± OluÅŸtur
```bash
mkdir -p src/preprocessing/scalers
touch src/preprocessing/__init__.py
touch src/preprocessing/base.py
touch src/preprocessing/preprocessor.py
touch src/preprocessing/scalers/__init__.py
touch src/preprocessing/scalers/standard.py
touch src/preprocessing/scalers/minmax.py
touch src/preprocessing/scalers/robust.py
touch src/preprocessing/scalers/quantile.py
```

### AdÄ±m 2: BaseScaler'Ä± Implement Et
- Abstract base class
- Common functionality
- Interface definition

### AdÄ±m 3: Concrete Scalers'Ä± Implement Et
- StandardScaler
- RobustScaler (Ã¶ncelikli)
- MinMaxScaler
- QuantileTransformer

### AdÄ±m 4: Preprocessor'Ä± Implement Et
- Ana sÄ±nÄ±f
- Config entegrasyonu
- Save/load functionality

### AdÄ±m 5: Config'e PreprocessingConfig Ekle
- PreprocessingConfig dataclass
- Config sÄ±nÄ±fÄ±na entegrasyon

### AdÄ±m 6: Unit Testler Yaz
- BaseScaler testleri
- Her scaler iÃ§in testler
- Preprocessor testleri
- Integration testleri

### AdÄ±m 7: DokÃ¼mantasyon
- Docstring'ler
- README gÃ¼ncellemesi
- Usage examples

### AdÄ±m 8: Integration
- Feature engineering pipeline'Ä±na entegre et
- Model training pipeline'Ä±na entegre et (gelecekte)

## âœ… Test SenaryolarÄ±

### Test 1: Basic Functionality
```python
def test_basic_scaling():
    df = create_test_dataframe()
    preprocessor = Preprocessor()
    df_scaled = preprocessor.fit_transform(df)
    
    assert df_scaled.shape == df.shape
    assert 'target' not in preprocessor.scaler.feature_columns
```

### Test 2: Train/Test Split
```python
def test_train_test_split():
    X_train, X_test = train_test_split(X, test_size=0.2)
    
    preprocessor = Preprocessor()
    X_train_scaled = preprocessor.fit_transform(X_train)
    X_test_scaled = preprocessor.transform(X_test)
    
    # Test data should not affect scaler
    assert preprocessor.scaler is not None
```

### Test 3: Exclude Columns
```python
def test_exclude_columns():
    df = create_test_dataframe()
    preprocessor = Preprocessor()
    df_scaled = preprocessor.fit_transform(df)
    
    # Excluded columns should not be scaled
    assert df_scaled['target'].equals(df['target'])
    assert df_scaled['datetime'].equals(df['datetime'])
```

### Test 4: Save/Load
```python
def test_save_load():
    preprocessor = Preprocessor()
    preprocessor.fit(df_train)
    preprocessor.save_scaler('test_scaler.pkl')
    
    preprocessor2 = Preprocessor()
    preprocessor2.load_scaler('test_scaler.pkl')
    df_scaled = preprocessor2.transform(df_test)
    
    assert preprocessor2.scaler is not None
```

## ğŸ¯ Ã–ncelik SÄ±rasÄ±

1. **YÃ¼ksek Ã–ncelik**:
   - BaseScaler abstract class
   - RobustScaler (en Ã¶nemli)
   - Preprocessor ana sÄ±nÄ±f
   - Config entegrasyonu

2. **Orta Ã–ncelik**:
   - StandardScaler, MinMaxScaler
   - Save/load functionality
   - Unit testler

3. **DÃ¼ÅŸÃ¼k Ã–ncelik**:
   - QuantileTransformer
   - Advanced features
   - Integration testleri

## ğŸ“Š Beklenen SonuÃ§lar

### Performans Metrikleri
- LightGBM iÃ§in minimal etki (tree-based)
- Gelecek modeller iÃ§in kritik fayda
- Feature importance daha anlamlÄ±

### Kod Kalitesi
- ModÃ¼ler yapÄ±
- Test edilebilir
- GeniÅŸletilebilir
- Production-ready

### KullanÄ±cÄ± Deneyimi
- Kolay kullanÄ±m
- Config ile kontrol
- Otomatik exclude columns
- Clear logging

