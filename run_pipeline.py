"""
End-to-end ML Pipeline Runner
TÃ¼m adÄ±mlarÄ± sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±r: Data Collection â†’ Feature Engineering â†’ Model Training
"""

import sys
from pathlib import Path

# Proje root'unu Python path'ine ekle
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.data_collection import BitcoinDataCollector
from src.feature_engineering.base import FeatureEngineer
from src.model_training.trainer import ModelTrainer
from src.config import get_config
from src.logger import get_logger
import pandas as pd

logger = get_logger("MLProject.Pipeline")


def run_data_collection(config):
    """Veri toplama adÄ±mÄ±"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š STEP 1: DATA COLLECTION")
    logger.info("=" * 60)

    try:
        collector = BitcoinDataCollector()

        # Veri Ã§ek: Config'den tarih aralÄ±ÄŸÄ± ve interval alÄ±nÄ±r
        logger.info("ğŸ”„ Bitcoin verileri Binance'den Ã§ekiliyor...")
        collector.fetch_data(
            interval=config.data_collection.main_interval,
            start_date=config.data_collection.main_start_date,
            end_date=config.data_collection.main_end_date,
        )

        # Kaydet (config'den dizin yolu kullanÄ±lÄ±r)
        filepath = collector.save_data()
        logger.info(f"ğŸ’¾ Veri kaydedildi: {filepath}")

        if collector.data is not None:
            logger.info(
                f"ğŸ“Š Veri Ã¶zeti: {len(collector.data)} satÄ±r, {len(collector.data.columns)} sÃ¼tun"
            )

        logger.info("âœ… Data collection tamamlandÄ±!")
        return True
    except Exception as e:
        logger.error(f"âŒ Data collection hatasÄ±: {e}")
        import traceback

        logger.error(traceback.format_exc())
        return False


def run_feature_engineering(config):
    """Feature engineering adÄ±mÄ±"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ”§ STEP 2: FEATURE ENGINEERING")
    logger.info("=" * 60)

    try:
        # Raw data yÃ¼kle (son Ã§ekilen veriyi kullan)
        raw_data_dir = config.paths.raw_data_dir
        raw_files = sorted(
            raw_data_dir.glob("*.csv"), key=lambda x: x.stat().st_mtime, reverse=True
        )

        if not raw_files:
            logger.error("âŒ Raw data bulunamadÄ±. Ã–nce veri Ã§ekin.")
            return False

        raw_file = raw_files[0]
        logger.info(f"ğŸ“‚ Raw data yÃ¼kleniyor: {raw_file}")

        df_raw = pd.read_csv(raw_file)
        df_raw["datetime"] = pd.to_datetime(df_raw["datetime"])

        logger.info(f"ğŸ“Š Raw data: {len(df_raw)} satÄ±r, {len(df_raw.columns)} sÃ¼tun")

        # Feature engineering
        fe = FeatureEngineer(config)
        df_processed = fe.create_features(df_raw)

        # Kaydet
        filepath = fe.save_processed_data(df_processed)

        logger.info("âœ… Feature engineering tamamlandÄ±!")
        logger.info(f"ğŸ“Š Ã–zet:")
        logger.info(f"   Raw data: {len(df_raw)} satÄ±r")
        logger.info(f"   Processed data: {len(df_processed)} satÄ±r")
        logger.info(f"   Feature sayÄ±sÄ±: {len(df_processed.columns)}")
        logger.info(f"   KayÄ±t yolu: {filepath}")
        return True
    except Exception as e:
        logger.error(f"âŒ Feature engineering hatasÄ±: {e}")
        import traceback

        logger.error(traceback.format_exc())
        return False


def run_model_training(config):
    """Model training adÄ±mÄ±"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ¤– STEP 3: MODEL TRAINING")
    logger.info("=" * 60)

    try:
        # Processed data yÃ¼kle (son iÅŸlenen veriyi kullan)
        processed_data_dir = config.paths.processed_data_dir
        processed_files = sorted(
            processed_data_dir.glob("*.csv"),
            key=lambda x: x.stat().st_mtime,
            reverse=True,
        )

        if not processed_files:
            logger.error(
                "âŒ Processed data bulunamadÄ±. Ã–nce feature engineering yapÄ±n."
            )
            return False

        processed_file = processed_files[0]
        logger.info(f"ğŸ“‚ Processed data yÃ¼kleniyor: {processed_file}")

        df_processed = pd.read_csv(processed_file)
        df_processed["datetime"] = pd.to_datetime(df_processed["datetime"])

        logger.info(
            f"ğŸ“Š Processed data: {len(df_processed)} satÄ±r, {len(df_processed.columns)} sÃ¼tun"
        )

        # Model training
        trainer = ModelTrainer(config)
        trainer.train(df_processed)

        # Model kaydet
        if config.model.save_model:
            filepath = trainer.save_model()
            logger.info(f"\nğŸ’¾ Model kaydedildi: {filepath}")

        logger.info("âœ… Model training tamamlandÄ±!")
        return True
    except Exception as e:
        logger.error(f"âŒ Model training hatasÄ±: {e}")
        import traceback

        logger.error(traceback.format_exc())
        return False


def run_full_pipeline(enable_data_collection=False, skip_feature_engineering=False):
    """
    TÃ¼m pipeline'Ä± Ã§alÄ±ÅŸtÄ±r

    Args:
        enable_data_collection: True ise data collection adÄ±mÄ±nÄ± Ã§alÄ±ÅŸtÄ±r (varsayÄ±lan: False)
        skip_feature_engineering: True ise feature engineering adÄ±mÄ±nÄ± atla
    """
    config = get_config()

    logger.info("=" * 60)
    logger.info("ğŸš€ FULL ML PIPELINE")
    logger.info("=" * 60)
    logger.info(f"   Enable Data Collection: {enable_data_collection}")
    logger.info(f"   Skip Feature Engineering: {skip_feature_engineering}")
    logger.info("=" * 60)

    success = True

    # 1. Data Collection (varsayÄ±lan olarak kapalÄ± - manuel veri Ã§ekme iÃ§in)
    if enable_data_collection:
        if not run_data_collection(config):
            logger.error("âŒ Pipeline data collection adÄ±mÄ±nda durdu!")
            return False
    else:
        logger.info("\nâ­ï¸  Data collection adÄ±mÄ± atlandÄ± (veri Ã§ekme manuel yapÄ±lmalÄ±)")

    # 2. Feature Engineering
    if not skip_feature_engineering:
        if not run_feature_engineering(config):
            logger.error("âŒ Pipeline feature engineering adÄ±mÄ±nda durdu!")
            return False
    else:
        logger.info(
            "\nâ­ï¸  Feature engineering adÄ±mÄ± atlandÄ± (skip_feature_engineering=True)"
        )

    # 3. Model Training
    if not run_model_training(config):
        logger.error("âŒ Pipeline model training adÄ±mÄ±nda durdu!")
        return False

    logger.info("\n" + "=" * 60)
    logger.info("âœ… FULL PIPELINE COMPLETED!")
    logger.info("=" * 60)

    return True


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Run full ML Pipeline")
    parser.add_argument(
        "--enable-data-collection",
        action="store_true",
        help="Enable data collection step (default: disabled - manual data collection)",
    )
    parser.add_argument(
        "--skip-feature-engineering",
        action="store_true",
        help="Skip feature engineering step",
    )

    args = parser.parse_args()

    success = run_full_pipeline(
        enable_data_collection=args.enable_data_collection,
        skip_feature_engineering=args.skip_feature_engineering,
    )

    sys.exit(0 if success else 1)
