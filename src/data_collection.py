"""
Bitcoin fiyat verilerini Binance API'den toplama modÃ¼lÃ¼.
"""

import pandas as pd
import ccxt
import pandas_ta as ta
from datetime import datetime, timedelta
from typing import Optional
import os
import time
from .config import get_config
from .logger import get_logger

# Logger'Ä± modÃ¼l seviyesinde oluÅŸtur
logger = get_logger("MLProject.DataCollection")


class BitcoinDataCollector:
    """Bitcoin fiyat verilerini Binance'den toplayan sÄ±nÄ±f."""

    def __init__(self, symbol: Optional[str] = None):
        """
        Args:
            symbol: Bitcoin sembolÃ¼ (None ise config'den alÄ±nÄ±r)
        """
        self.config = get_config()
        self.symbol = symbol or self.config.data_collection.default_symbol

        # Exchange oluÅŸtur
        exchange_class = getattr(ccxt, self.config.exchange.name)
        exchange_params = {
            "enableRateLimit": self.config.exchange.enable_rate_limit,
            "options": {"defaultType": self.config.exchange.default_type},
        }

        # API keys varsa ekle
        if self.config.exchange.api_key:
            exchange_params["apiKey"] = self.config.exchange.api_key
        if self.config.exchange.api_secret:
            exchange_params["secret"] = self.config.exchange.api_secret
        if self.config.exchange.sandbox:
            exchange_params["sandbox"] = True

        self.exchange = exchange_class(exchange_params)
        self.data = None

    def _convert_interval(self, interval: str) -> str:
        """
        Standart interval formatÄ±nÄ± Binance formatÄ±na Ã§evirir.

        Args:
            interval: Standart format (1m, 5m, 15m, 30m, 1h, 4h, 1d, 1w)

        Returns:
            str: Binance formatÄ±
        """
        interval_map = self.config.data_collection.supported_intervals
        default_interval = self.config.data_collection.default_interval
        return interval_map.get(interval, default_interval)

    def fetch_data(
        self,
        interval: Optional[str] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        limit: Optional[int] = None,
    ) -> pd.DataFrame:
        """
        Bitcoin fiyat verilerini Binance API'den Ã§eker.

        Args:
            interval: Veri aralÄ±ÄŸÄ± (1m, 5m, 15m, 30m, 1h, 4h, 1d, 1w) (None ise config'den alÄ±nÄ±r)
            start_date: BaÅŸlangÄ±Ã§ tarihi (YYYY-MM-DD veya timestamp)
            end_date: BitiÅŸ tarihi (YYYY-MM-DD veya timestamp)
            limit: Her istekte Ã§ekilecek maksimum veri sayÄ±sÄ± (None ise config'den alÄ±nÄ±r)

        Returns:
            DataFrame: OHLCV verileri
        """
        # Config'den varsayÄ±lan deÄŸerleri al
        interval = interval or self.config.data_collection.default_interval
        limit = limit or self.config.data_collection.default_limit

        binance_interval = self._convert_interval(interval)

        # Tarihleri timestamp'e Ã§evir
        if start_date:
            if isinstance(start_date, str):
                start_timestamp = int(pd.Timestamp(start_date).timestamp() * 1000)
            else:
                start_timestamp = int(start_date * 1000)
        else:
            # Config'den varsayÄ±lan gÃ¼n sayÄ±sÄ±nÄ± al
            days_back = self.config.data_collection.default_days_back
            start_timestamp = int(
                (datetime.now() - timedelta(days=days_back)).timestamp() * 1000
            )

        if end_date:
            if isinstance(end_date, str):
                end_timestamp = int(pd.Timestamp(end_date).timestamp() * 1000)
            else:
                end_timestamp = int(end_date * 1000)
        else:
            end_timestamp = int(datetime.now().timestamp() * 1000)

        logger.info("ğŸ”„ Binance'den veri Ã§ekiliyor...")
        logger.info(f"ğŸ“Š Sembol: {self.symbol}")
        logger.info(f"â±ï¸  Interval: {interval} ({binance_interval})")
        logger.info(
            f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {datetime.fromtimestamp(start_timestamp/1000)} - {datetime.fromtimestamp(end_timestamp/1000)}"
        )

        all_ohlcv = []
        current_timestamp = start_timestamp

        # Config'den rate limiting deÄŸerlerini al
        request_delay = self.config.data_collection.request_delay
        if request_delay is None:
            request_delay = 0.1  # VarsayÄ±lan deÄŸer

        while current_timestamp < end_timestamp:
            try:
                ohlcv = self.exchange.fetch_ohlcv(
                    self.symbol, binance_interval, since=current_timestamp, limit=limit
                )

                if not ohlcv:
                    break

                all_ohlcv.extend(ohlcv)

                # Son Ã§ekilen verinin timestamp'ini al
                last_timestamp = ohlcv[-1][0]

                # EÄŸer aynÄ± timestamp'te kalÄ±yorsak, bir sonraki interval'e geÃ§
                if last_timestamp == current_timestamp:
                    # Interval'e gÃ¶re timestamp artÄ±r
                    interval_ms = self._get_interval_ms(binance_interval)
                    current_timestamp = last_timestamp + interval_ms
                else:
                    current_timestamp = last_timestamp + 1  # +1 ms

                # Rate limiting
                time.sleep(request_delay)

                # Ä°lerleme gÃ¶ster
                threshold = self.config.data_collection.progress_print_threshold
                if len(all_ohlcv) % threshold == 0:
                    logger.debug(f"   ğŸ“¥ {len(all_ohlcv)} mum Ã§ekildi...")

            except ccxt.NetworkError as e:
                # AÄŸ baÄŸlantÄ± hatasÄ±
                logger.warning(f"âš ï¸  AÄŸ hatasÄ±: {e}")
                logger.info("   Bekleniyor...")
                time.sleep(self.config.data_collection.error_retry_delay)
                continue
            except ccxt.ExchangeError as e:
                # Exchange API hatasÄ± (rate limit, invalid request, etc.)
                logger.warning(f"âš ï¸  Exchange hatasÄ±: {e}")
                logger.info("   Bekleniyor...")
                time.sleep(self.config.data_collection.error_retry_delay)
                continue
            except ccxt.RequestTimeout as e:
                # Ä°stek zaman aÅŸÄ±mÄ±
                logger.warning(f"âš ï¸  Ä°stek zaman aÅŸÄ±mÄ±: {e}")
                logger.info("   Bekleniyor...")
                time.sleep(self.config.data_collection.error_retry_delay)
                continue
            except ConnectionError as e:
                # Python ConnectionError
                logger.warning(f"âš ï¸  BaÄŸlantÄ± hatasÄ±: {e}")
                logger.info("   Bekleniyor...")
                time.sleep(self.config.data_collection.error_retry_delay)
                continue
            except TimeoutError as e:
                # Python TimeoutError
                logger.warning(f"âš ï¸  Zaman aÅŸÄ±mÄ±: {e}")
                logger.info("   Bekleniyor...")
                time.sleep(self.config.data_collection.error_retry_delay)
                continue
            except ValueError as e:
                # GeÃ§ersiz parametreler
                logger.error(f"âŒ GeÃ§ersiz parametre: {e}")
                raise  # ValueError'Ä± yeniden fÄ±rlat Ã§Ã¼nkÃ¼ bu dÃ¼zeltilemez bir hata
            except Exception as e:
                # DiÄŸer beklenmeyen hatalar iÃ§in genel exception (fallback)
                logger.warning(f"âš ï¸  Beklenmeyen hata: {type(e).__name__}: {e}")
                logger.info("   Bekleniyor...")
                time.sleep(self.config.data_collection.error_retry_delay)
                continue

        if not all_ohlcv:
            raise ValueError("Veri Ã§ekilemedi. LÃ¼tfen parametreleri kontrol edin.")

        # DataFrame oluÅŸtur
        df = pd.DataFrame(
            all_ohlcv, columns=["datetime", "open", "high", "low", "close", "volume"]
        )

        # Timestamp'i datetime'a Ã§evir
        df["datetime"] = pd.to_datetime(df["datetime"], unit="ms")

        # Duplicate'leri temizle
        df = df.drop_duplicates(subset=["datetime"])

        # Tarihe gÃ¶re sÄ±rala
        df = df.sort_values("datetime").reset_index(drop=True)

        # End date'e kadar filtrele
        df = df[df["datetime"] <= pd.Timestamp(end_timestamp, unit="ms")]

        self.data = df  # type: ignore[assignment]

        logger.info(f"âœ… {len(df)} satÄ±r veri Ã§ekildi.")
        logger.info(
            f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {df['datetime'].min()} - {df['datetime'].max()}"
        )

        return df

    def _get_interval_ms(self, interval: str) -> int:
        """Interval'i milisaniyeye Ã§evirir."""
        interval_ms_map = self.config.data_collection.interval_ms_map
        default_ms = self.config.data_collection.default_interval_ms
        return interval_ms_map.get(interval, default_ms)

    def calculate_technical_indicators(
        self, df: Optional[pd.DataFrame] = None
    ) -> pd.DataFrame:
        """
        Teknik gÃ¶stergeleri hesaplar.

        Args:
            df: DataFrame (None ise self.data kullanÄ±lÄ±r)

        Returns:
            DataFrame: Teknik gÃ¶stergelerle zenginleÅŸtirilmiÅŸ DataFrame
        """
        if df is None:
            if self.data is None:
                raise ValueError(
                    "Veri bulunamadÄ±. Ã–nce fetch_data() metodunu Ã§alÄ±ÅŸtÄ±rÄ±n."
                )
            df = self.data.copy()

        if df is None or df.empty:
            raise ValueError("Veri bulunamadÄ±. Ã–nce fetch_data() metodunu Ã§alÄ±ÅŸtÄ±rÄ±n.")

        # Datetime'Ä± index yap (pandas_ta iÃ§in gerekli)
        df = df.set_index("datetime") if "datetime" in df.columns else df

        logger.info("ğŸ“Š Teknik gÃ¶stergeler hesaplanÄ±yor...")

        ti_config = self.config.technical_indicators

        # Trend gÃ¶stergeleri - SMA
        for period in ti_config.sma_periods:
            df[f"sma_{period}"] = ta.sma(df["close"], length=period)

        # Trend gÃ¶stergeleri - EMA
        for period in ti_config.ema_periods:
            df[f"ema_{period}"] = ta.ema(df["close"], length=period)

        # Momentum gÃ¶stergeleri - RSI
        if ti_config.rsi_periods is not None:
            for idx, period in enumerate(ti_config.rsi_periods):
                if idx == 0:  # Ä°lk deÄŸer varsayÄ±lan 'rsi' adÄ±yla
                    df["rsi"] = ta.rsi(df["close"], length=period)
                else:
                    df[f"rsi_{period}"] = ta.rsi(df["close"], length=period)

        # MACD
        macd = ta.macd(
            df["close"],
            fast=ti_config.macd_fast,
            slow=ti_config.macd_slow,
            signal=ti_config.macd_signal,
        )
        if macd is not None and not macd.empty:
            df["macd"] = macd[
                f"MACD_{ti_config.macd_fast}_{ti_config.macd_slow}_{ti_config.macd_signal}"
            ]
            df["macd_signal"] = macd[
                f"MACDs_{ti_config.macd_fast}_{ti_config.macd_slow}_{ti_config.macd_signal}"
            ]
            df["macd_hist"] = macd[
                f"MACDh_{ti_config.macd_fast}_{ti_config.macd_slow}_{ti_config.macd_signal}"
            ]

        # Bollinger Bands
        # Note: pandas_ta bbands std parametresi dict bekliyor ama float da kabul ediyor
        bbands = ta.bbands(
            df["close"], length=ti_config.bb_length, std=ti_config.bb_std  # type: ignore[arg-type]
        )
        if bbands is not None and not bbands.empty:
            df["bb_upper"] = bbands[f"BBU_{ti_config.bb_length}_{ti_config.bb_std}"]
            df["bb_middle"] = bbands[f"BBM_{ti_config.bb_length}_{ti_config.bb_std}"]
            df["bb_lower"] = bbands[f"BBL_{ti_config.bb_length}_{ti_config.bb_std}"]
            df["bb_width"] = (
                bbands[f"BBU_{ti_config.bb_length}_{ti_config.bb_std}"]
                - bbands[f"BBL_{ti_config.bb_length}_{ti_config.bb_std}"]
            ) / bbands[f"BBM_{ti_config.bb_length}_{ti_config.bb_std}"]
            df["bb_position"] = (
                df["close"] - bbands[f"BBL_{ti_config.bb_length}_{ti_config.bb_std}"]
            ) / (
                bbands[f"BBU_{ti_config.bb_length}_{ti_config.bb_std}"]
                - bbands[f"BBL_{ti_config.bb_length}_{ti_config.bb_std}"]
            )

        # Stochastic Oscillator
        stoch = ta.stoch(
            df["high"],
            df["low"],
            df["close"],
            k=ti_config.stoch_k_period,
            d=ti_config.stoch_d_period,
            smooth_k=ti_config.stoch_smooth,
        )
        if stoch is not None and not stoch.empty:
            df["stoch_k"] = stoch[
                f"STOCHk_{ti_config.stoch_k_period}_{ti_config.stoch_smooth}_{ti_config.stoch_d_period}"
            ]
            df["stoch_d"] = stoch[
                f"STOCHd_{ti_config.stoch_k_period}_{ti_config.stoch_smooth}_{ti_config.stoch_d_period}"
            ]

        # ATR (Average True Range) - Volatilite gÃ¶stergesi
        df["atr"] = ta.atr(
            df["high"], df["low"], df["close"], length=ti_config.atr_period
        )

        # ADX (Average Directional Index) - Trend gÃ¼cÃ¼
        adx = ta.adx(df["high"], df["low"], df["close"], length=ti_config.adx_period)
        if adx is not None and not adx.empty:
            df["adx"] = adx[f"ADX_{ti_config.adx_period}"]
            df["adx_pos"] = adx[f"DMP_{ti_config.adx_period}"]
            df["adx_neg"] = adx[f"DMN_{ti_config.adx_period}"]

        # Volume gÃ¶stergeleri
        df["volume_sma"] = ta.sma(df["volume"], length=ti_config.volume_sma_period)
        df["volume_ratio"] = df["volume"] / df["volume_sma"]

        # Fiyat deÄŸiÅŸimleri
        df["returns"] = df["close"].pct_change()
        for period in ti_config.returns_periods:
            df[f"returns_{period}"] = df["close"].pct_change(period)

        # YÃ¼ksek/DÃ¼ÅŸÃ¼k oranlarÄ±
        df["high_low_ratio"] = df["high"] / df["low"]
        df["close_open_ratio"] = df["close"] / df["open"]

        # Fiyat pozisyonu (gÃ¼nlÃ¼k range iÃ§indeki konumu)
        df["price_position"] = (df["close"] - df["low"]) / (df["high"] - df["low"])

        # Lag features (geÃ§miÅŸ deÄŸerler)
        for lag in ti_config.lag_periods:
            df[f"close_lag_{lag}"] = df["close"].shift(lag)
            df[f"volume_lag_{lag}"] = df["volume"].shift(lag)

        # Rolling istatistikler
        for window in ti_config.rolling_windows:
            df[f"volatility_{window}"] = df["returns"].rolling(window=window).std()
            df[f"close_max_{window}"] = df["close"].rolling(window=window).max()
            df[f"close_min_{window}"] = df["close"].rolling(window=window).min()

        # Index'i tekrar sÃ¼tun yap
        df.reset_index(inplace=True)

        # NaN deÄŸerleri temizle
        df = df.dropna()

        logger.info(f"âœ… {len(df.columns)} sÃ¼tunlu veri seti hazÄ±rlandÄ±.")
        logger.info(f"ğŸ“Š {len(df)} satÄ±r veri kaldÄ± (NaN temizleme sonrasÄ±).")

        self.data = df  # type: ignore[assignment]
        return df

    def save_data(self, filepath: Optional[str] = None) -> str:
        """
        Veriyi CSV olarak data/raw klasÃ¶rÃ¼ne kaydeder.

        Args:
            filepath: KayÄ±t yolu (None ise otomatik oluÅŸturulur)

        Returns:
            str: Kaydedilen dosya yolu
        """
        if self.data is None or self.data.empty:
            raise ValueError("Kaydedilecek veri bulunamadÄ±.")

        if filepath is None:
            # Config'den dizin yolunu al
            raw_data_dir = self.config.paths.raw_data_dir
            os.makedirs(raw_data_dir, exist_ok=True)
            symbol_clean = self.symbol.replace("/", "_")
            start_date = self.data["datetime"].min().strftime("%Y%m%d")
            end_date = self.data["datetime"].max().strftime("%Y%m%d")
            filepath = raw_data_dir / f"{symbol_clean}_{start_date}_{end_date}.csv"
            filepath = str(filepath)

        # KlasÃ¶r yoksa oluÅŸtur
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        self.data.to_csv(filepath, index=False)
        logger.info(f"ğŸ’¾ Veri kaydedildi: {filepath}")
        logger.info(f"ğŸ“ Dosya boyutu: {os.path.getsize(filepath) / 1024:.2f} KB")

        return filepath

    def load_data(self, filepath: str) -> pd.DataFrame:
        """
        CSV dosyasÄ±ndan veri yÃ¼kler.

        Args:
            filepath: Dosya yolu

        Returns:
            DataFrame: YÃ¼klenen veri
        """
        self.data = pd.read_csv(filepath)  # type: ignore[assignment]
        if self.data is not None and "datetime" in self.data.columns:
            self.data["datetime"] = pd.to_datetime(self.data["datetime"])
        logger.info(f"ğŸ“‚ Veri yÃ¼klendi: {filepath}")
        if self.data is not None:
            logger.info(f"ğŸ“Š {len(self.data)} satÄ±r, {len(self.data.columns)} sÃ¼tun")
            return self.data
        else:
            raise ValueError("Veri yÃ¼klenemedi")


def main():
    """Bitcoin verilerini Ã§eker - tarih aralÄ±ÄŸÄ± ve interval config'den alÄ±nÄ±r"""
    config = get_config()

    # Config'den varsayÄ±lan sembol kullanÄ±lÄ±r
    collector = BitcoinDataCollector()

    # Veri Ã§ek: Config'den tarih aralÄ±ÄŸÄ± ve interval alÄ±nÄ±r
    logger.info("ğŸ”„ Bitcoin verileri Binance'den Ã§ekiliyor...")
    collector.fetch_data(
        interval=config.data_collection.main_interval,
        start_date=config.data_collection.main_start_date,
        end_date=config.data_collection.main_end_date,
    )

    # Kaydet (config'den dizin yolu kullanÄ±lÄ±r)
    filepath = collector.save_data()
    logger.info(f"ğŸ’¾ Veri kaydedildi: {filepath}")

    logger.info("\nâœ… Veri toplama iÅŸlemi tamamlandÄ±!")
    if collector.data is not None:
        logger.info("\nğŸ“Š Veri Ã¶zeti:")
        logger.debug(f"\n{collector.data.describe()}")
        logger.info("\nğŸ“ˆ Ä°lk 5 satÄ±r:")
        logger.debug(f"\n{collector.data.head()}")
        logger.info("\nğŸ“ˆ Son 5 satÄ±r:")
        logger.debug(f"\n{collector.data.tail()}")


if __name__ == "__main__":
    main()
