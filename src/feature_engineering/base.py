"""
Feature Engineering ana sÄ±nÄ±fÄ± - ModÃ¼ler yapÄ±
"""

import pandas as pd
from typing import Optional
import os
from ..config import get_config
from ..logger import get_logger

# ModÃ¼ller
from .indicators import (
    TrendIndicators,
    MomentumIndicators,
    VolatilityIndicators,
    VolumeIndicators,
    PriceFeatures,
)
from .targets import BinaryTarget, MulticlassTarget, RegressionTarget
from .features import TimeFeatures

# Logger
logger = get_logger("MLProject.FeatureEngineering")


class FeatureEngineer:
    """Feature engineering sÄ±nÄ±fÄ± - ModÃ¼ler yapÄ±"""

    def __init__(self, config=None):
        """
        Args:
            config: Config objesi (None ise get_config() kullanÄ±lÄ±r)
        """
        self.config = config or get_config()
        self.data = None

    def create_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Teknik gÃ¶stergeleri hesaplar (modÃ¼ler yapÄ± kullanarak).

        Args:
            df: DataFrame (OHLCV verisi)

        Returns:
            DataFrame: Teknik gÃ¶stergelerle zenginleÅŸtirilmiÅŸ DataFrame
        """
        df = df.copy()

        if df.empty:
            raise ValueError("DataFrame boÅŸ.")

        # Datetime'Ä± index yap (pandas_ta iÃ§in gerekli)
        df = df.set_index("datetime") if "datetime" in df.columns else df

        logger.info("ğŸ“Š Teknik gÃ¶stergeler hesaplanÄ±yor...")

        ti_config = self.config.technical_indicators

        # Trend gÃ¶stergeleri
        if ti_config.sma_periods is not None and ti_config.ema_periods is not None:
            df = TrendIndicators.create_all(
                df, ti_config.sma_periods, ti_config.ema_periods
            )

        # Momentum gÃ¶stergeleri
        if ti_config.rsi_periods is not None:
            df = MomentumIndicators.create_all(
                df,
                ti_config.rsi_periods,
                ti_config.macd_fast,
                ti_config.macd_slow,
                ti_config.macd_signal,
                ti_config.stoch_k_period,
                ti_config.stoch_d_period,
                ti_config.stoch_smooth,
            )

        # Volatilite gÃ¶stergeleri
        df = VolatilityIndicators.create_all(
            df,
            ti_config.bb_length,
            ti_config.bb_std,
            ti_config.atr_period,
            ti_config.adx_period,
        )

        # Volume gÃ¶stergeleri
        df = VolumeIndicators.create_all(df, ti_config.volume_sma_period)

        # Fiyat feature'larÄ±
        if (
            ti_config.returns_periods is not None
            and ti_config.lag_periods is not None
            and ti_config.rolling_windows is not None
        ):
            df = PriceFeatures.create_all(
                df,
                ti_config.returns_periods,
                ti_config.lag_periods,
                ti_config.rolling_windows,
            )

        # Index'i tekrar sÃ¼tun yap
        df.reset_index(inplace=True)

        logger.info(
            f"âœ… Teknik gÃ¶stergeler hesaplandÄ±. Toplam {len(df.columns)} sÃ¼tun."
        )

        return df

    def create_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Zaman bazlÄ± feature'larÄ± oluÅŸturur.

        Args:
            df: DataFrame (datetime sÃ¼tunu olmalÄ±)

        Returns:
            DataFrame: Zaman feature'larÄ±yla zenginleÅŸtirilmiÅŸ DataFrame
        """
        logger.info("ğŸ• Zaman bazlÄ± feature'lar oluÅŸturuluyor...")
        df = TimeFeatures.create(df)
        logger.info("âœ… Zaman feature'larÄ± oluÅŸturuldu.")
        return df

    def create_target_variable(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Target variable oluÅŸturur (modÃ¼ler yapÄ± kullanarak).

        Args:
            df: DataFrame (datetime ve close sÃ¼tunlarÄ± olmalÄ±)

        Returns:
            DataFrame: Target variable ile zenginleÅŸtirilmiÅŸ DataFrame
        """
        df = df.copy()

        if "close" not in df.columns:
            raise ValueError("DataFrame'de 'close' sÃ¼tunu bulunamadÄ±.")

        fe_config = self.config.feature_engineering

        logger.info("ğŸ¯ Target variable oluÅŸturuluyor...")
        logger.info(f"   Prediction horizon: {fe_config.prediction_horizon} saat")
        logger.info(f"   Threshold: {fe_config.target_threshold*100:.2f}%")

        # Forward-looking return hesapla
        from .targets.base import calculate_future_return

        future_return = calculate_future_return(df, fe_config.prediction_horizon)

        # Target variable oluÅŸtur (strategy pattern)
        if fe_config.target_type == "binary":
            df = BinaryTarget.create(df, future_return, fe_config.target_threshold)
            df = df.iloc[: -fe_config.prediction_horizon].copy()

            logger.info("âœ… Binary target oluÅŸturuldu.")
            logger.info(
                f"   Long (1): {df['target'].sum()} satÄ±r ({df['target'].sum()/len(df)*100:.2f}%)"
            )
            logger.info(
                f"   Short (0): {(df['target']==0).sum()} satÄ±r ({(df['target']==0).sum()/len(df)*100:.2f}%)"
            )

        elif fe_config.target_type == "multi_class":
            df = MulticlassTarget.create(
                df,
                future_return,
                fe_config.target_threshold,
                fe_config.drop_hold_class,
            )
            df = df.iloc[: -fe_config.prediction_horizon].copy()

            logger.info("âœ… Multi-class target oluÅŸturuldu.")
            logger.info(f"   Long (1): {(df['target']==1).sum()} satÄ±r")
            logger.info(f"   Short (-1): {(df['target']==-1).sum()} satÄ±r")
            logger.info(f"   Hold (0): {(df['target']==0).sum()} satÄ±r")

        elif fe_config.target_type == "regression":
            df = RegressionTarget.create(df, future_return)
            df = df.iloc[: -fe_config.prediction_horizon].copy()
            logger.info("âœ… Regression target oluÅŸturuldu.")

        else:
            raise ValueError(f"GeÃ§ersiz target_type: {fe_config.target_type}")

        logger.info(f"ğŸ“Š {len(df)} satÄ±r kaldÄ± (target oluÅŸturma sonrasÄ±).")

        return df

    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Veriyi temizler (missing values, duplicates).

        Args:
            df: DataFrame

        Returns:
            DataFrame: TemizlenmiÅŸ DataFrame
        """
        df = df.copy()

        fe_config = self.config.feature_engineering

        logger.info("ğŸ§¹ Veri temizleniyor...")

        initial_rows = len(df)

        # Duplicate kontrolÃ¼
        duplicates = df.duplicated(subset=["datetime"]).sum()
        if duplicates > 0:
            logger.warning(f"âš ï¸  {duplicates} duplicate satÄ±r bulundu, Ã§Ä±karÄ±lÄ±yor...")
            df = df.drop_duplicates(subset=["datetime"])

        # Missing values
        if fe_config.drop_na:
            nan_before = df.isnull().sum().sum()
            df = df.dropna()
            nan_after = df.isnull().sum().sum()
            logger.info(f"   NaN deÄŸerler temizlendi: {nan_before} â†’ {nan_after}")

        final_rows = len(df)
        logger.info(
            f"âœ… Veri temizlendi: {initial_rows} â†’ {final_rows} satÄ±r ({final_rows-initial_rows} satÄ±r Ã§Ä±karÄ±ldÄ±)."
        )

        return df

    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        TÃ¼m feature'larÄ± oluÅŸturur (ana metod - pipeline).

        Args:
            df: DataFrame (OHLCV verisi)

        Returns:
            DataFrame: TÃ¼m feature'larla zenginleÅŸtirilmiÅŸ DataFrame
        """
        logger.info("ğŸš€ Feature engineering baÅŸlatÄ±lÄ±yor...")
        logger.info(f"ğŸ“Š BaÅŸlangÄ±Ã§: {len(df)} satÄ±r, {len(df.columns)} sÃ¼tun")

        # Teknik gÃ¶stergeler
        df = self.create_technical_indicators(df)

        # Zaman feature'larÄ± (opsiyonel)
        fe_config = self.config.feature_engineering
        if fe_config.include_time_features:
            df = self.create_time_features(df)

        # Target variable
        df = self.create_target_variable(df)

        # Veri temizleme
        df = self.clean_data(df)

        # Preprocessing (scaling) - Opsiyonel, genelde train/test split'ten sonra kullanÄ±lmalÄ±
        fe_config = self.config.feature_engineering
        if fe_config.enable_scaling_in_pipeline:
            df = self.scale_features(df)

        self.data = df  # type: ignore[assignment]

        logger.info("âœ… Feature engineering tamamlandÄ±!")
        logger.info(f"ğŸ“Š SonuÃ§: {len(df)} satÄ±r, {len(df.columns)} sÃ¼tun")

        return df

    def scale_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Feature scaling (opsiyonel, genelde train/test split'ten sonra kullanÄ±lmalÄ±).

        âš ï¸  DÄ°KKAT: Bu metod tÃ¼m veri Ã¼zerinde fit eder, data leakage riski taÅŸÄ±r.
        Production iÃ§in train/test split'ten sonra Preprocessor kullanÄ±lmalÄ±.

        Args:
            df: DataFrame

        Returns:
            DataFrame: Scaled DataFrame
        """
        from ..preprocessing import Preprocessor

        logger.info("ğŸ”§ Feature scaling yapÄ±lÄ±yor (pipeline iÃ§inde)...")
        logger.warning(
            "âš ï¸  DÄ°KKAT: Bu yaklaÅŸÄ±m data leakage riski taÅŸÄ±r. "
            "Production iÃ§in train/test split'ten sonra scaling yapÄ±lmalÄ±."
        )

        preprocessor = Preprocessor(config=self.config)
        df_scaled = preprocessor.fit_transform(df)

        return df_scaled

    def save_processed_data(
        self, df: Optional[pd.DataFrame] = None, filepath: Optional[str] = None
    ) -> str:
        """
        Processed data'yÄ± CSV olarak kaydeder.

        Args:
            df: DataFrame (None ise self.data kullanÄ±lÄ±r)
            filepath: KayÄ±t yolu (None ise otomatik oluÅŸturulur)

        Returns:
            str: Kaydedilen dosya yolu
        """
        if df is None:
            df = self.data

        if df is None or df.empty:
            raise ValueError("Kaydedilecek veri bulunamadÄ±.")

        if filepath is None:
            # Config'den dizin yolunu al
            processed_data_dir = self.config.paths.processed_data_dir
            os.makedirs(processed_data_dir, exist_ok=True)

            # Dosya adÄ± oluÅŸtur
            start_date = df["datetime"].min().strftime("%Y%m%d")
            end_date = df["datetime"].max().strftime("%Y%m%d")
            fe_config = self.config.feature_engineering
            filepath = (
                processed_data_dir
                / f"processed_{start_date}_{end_date}_h{fe_config.prediction_horizon}_t{fe_config.target_threshold}.csv"
            )
            filepath = str(filepath)

        # KlasÃ¶r yoksa oluÅŸtur
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        df.to_csv(filepath, index=False)
        logger.info(f"ğŸ’¾ Processed data kaydedildi: {filepath}")
        logger.info(f"ğŸ“ Dosya boyutu: {os.path.getsize(filepath) / 1024:.2f} KB")

        return filepath

    def load_processed_data(self, filepath: str) -> pd.DataFrame:
        """
        Processed data'yÄ± CSV'den yÃ¼kler.

        Args:
            filepath: Dosya yolu

        Returns:
            DataFrame: YÃ¼klenen veri
        """
        self.data = pd.read_csv(filepath)  # type: ignore[assignment]
        if self.data is not None and "datetime" in self.data.columns:
            self.data["datetime"] = pd.to_datetime(self.data["datetime"])
        logger.info(f"ğŸ“‚ Processed data yÃ¼klendi: {filepath}")
        if self.data is not None:
            logger.info(f"ğŸ“Š {len(self.data)} satÄ±r, {len(self.data.columns)} sÃ¼tun")
            return self.data  # type: ignore[no-any-return]
        else:
            raise ValueError("Veri yÃ¼klenemedi")
